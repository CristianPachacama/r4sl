# Generative Models

In this chapter, we continue our discussion of classification methods. We introduce three new methods, each a **generative** method. This in comparison to logistic regression, which is a **discriminative** method.

Generative methods model the joint probability, $p(x, y)$, often by assuming some distribution for the conditional distribution of $X$ given $Y$, $f(x \mid y)$. Bayes theorem is then applied to classify according to $p(y \mid x)$. Discriminative methods directly model this conditional, $p(y \mid x)$. A detailed discussion and anlysis can be found in [Ng and Jordan, 2002](https://papers.nips.cc/paper/2020-on-discriminative-vs-generative-classifiers-a-comparison-of-logistic-regression-and-naive-bayes.pdf).

To illustrate these new methods, we return to the iris data, which you may remember has three classes.

```{r}
set.seed(430)
iris_obs = nrow(iris)
iris_index = sample(iris_obs, size = trunc(0.50 * iris_obs))
# iris_index = sample(iris_obs, size = trunc(0.10 * iris_obs))
iris_train = iris[iris_index, ]
iris_test = iris[-iris_index, ]
```


```{r, fig.height=8, fig.width=8}
caret::featurePlot(x = iris_train[, c("Sepal.Length", "Sepal.Width", 
                               "Petal.Length", "Petal.Width")], 
            y = iris_train$Species,
            plot = "density", 
            scales = list(x = list(relation = "free"), 
                          y = list(relation = "free")), 
            adjust = 1.5, 
            pch = "|", 
            layout = c(2, 2), 
            auto.key = list(columns = 3))
```

```{r, fig.height=8, fig.width=8}

caret::featurePlot(x = iris_train[, c("Sepal.Length", "Sepal.Width", 
                               "Petal.Length", "Petal.Width")], 
            y = iris_train$Species,
            plot = "ellipse",
            auto.key = list(columns = 3))
```


```{r, fig.height=4, fig.width=7}
caret::featurePlot(x = iris_train[, c("Sepal.Length", "Sepal.Width", 
                               "Petal.Length", "Petal.Width")], 
            y = iris_train$Species,
                  plot = "box",
                  scales = list(y = list(relation="free"),
                                x = list(rot = 90)),
                  layout = c(4, 1))
```


## Linear Discriminant Analysis

```{r}
library(MASS)
iris_lda = lda(Species ~ ., data = iris_train)
iris_lda
```


```{r}
names(predict(iris_lda, iris_train))
head(predict(iris_lda, iris_train)$class, n = 10)
head(predict(iris_lda, iris_train)$posterior, n = 10)
```

```{r}
iris_lda_train_pred = predict(iris_lda, iris_train)$class
iris_lda_test_pred = predict(iris_lda, iris_test)$class
```

```{r}
accuracy = function(actual, predicted) {
  mean(actual == predicted)
}
```

```{r}
accuracy(predicted = iris_lda_train_pred, actual = iris_train$Species)
accuracy(predicted = iris_lda_test_pred, actual = iris_test$Species)
```

```{r}
table(predicted = iris_lda_test_pred, actual = iris_test$Species)
```

- TODO: predicted two classes perfectly

```{r}
iris_lda_flat = lda(Species ~ ., data = iris_train, prior = c(1, 1, 1) / 3)
iris_lda_flat
```



```{r}
iris_lda_flat_train_pred = predict(iris_lda_flat, iris_train)$class
iris_lda_flat_test_pred = predict(iris_lda_flat, iris_test)$class
```


```{r}
accuracy(predicted = iris_lda_flat_train_pred, actual = iris_train$Species)
accuracy(predicted = iris_lda_flat_test_pred, actual = iris_test$Species)
```







## Quadratic Discriminant Analysis


```{r}
iris_qda = qda(Species ~ ., data = iris_train)
iris_qda
```

- TODO: number of parameters vs number of obs in each class


```{r}
iris_qda_train_pred = predict(iris_qda, iris_train)$class
iris_qda_test_pred = predict(iris_qda, iris_test)$class
```



```{r}
accuracy(predicted = iris_qda_train_pred, actual = iris_train$Species)
accuracy(predicted = iris_qda_test_pred, actual = iris_test$Species)
```


```{r}
table(predicted = iris_qda_test_pred, actual = iris_test$Species)
```

- TODO: lda with quadratic terms


## Naive Bayes



```{r}
library(e1071)
iris_nb = naiveBayes(Species ~ ., data = iris_train)
iris_nb
```

- TODO: how mean estimates are the same as above

```{r}
head(predict(iris_nb, iris_train))
head(predict(iris_nb, iris_train, type = "class"))
head(predict(iris_nb, iris_train, type = "raw"))
```

```{r}
iris_nb_train_pred = predict(iris_nb, iris_train)
iris_nb_test_pred = predict(iris_nb, iris_test)
```



```{r}
accuracy(predicted = iris_nb_train_pred, actual = iris_train$Species)
accuracy(predicted = iris_nb_test_pred, actual = iris_test$Species)
```

```{r}
table(predicted = iris_nb_test_pred, actual = iris_test$Species)


```







- TODO: results compaison, not meaningful with this data, note differences to expect, nb good with large p, etc





