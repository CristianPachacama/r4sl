# k-Nearest Neighbors




- TODO: non-parametric method
- TODO: but tuning parameter
    - how the method should be fit, not a result of the fitting
    
## Classification

```{r}
library(ISLR)
library(class)
library(MASS)
```

- TODO: `Default` comes from `ISLR`
- TODO: `knn()` comes from `class`
- TODO: `Boston` comes from `MASS`

- TODO: need to arrange data for `knn()`
- TODO: note that input (predictors) must be numeric

```{r}
set.seed(42)
Default$student = as.numeric(Default$student) - 1
default_index = sample(nrow(Default), 5000)
default_train = Default[default_index, ]
default_test = Default[-default_index, ]
```

- TODO: split data into X and Y for knn

```{r}
# training data
X_default_train = default_train[, -1]
y_default_train = default_train[, 1]

# testing data
X_default_test = default_test[, -1]
y_default_test = default_test[, 1]
```

```{r}
knn(train = X_default_train, test = X_default_test, cl = y_default_train, k = 3)
```

- TODO: no "training" done, so `knn()` basically replaces `predict()`
- TODO: fast @ train, slow @ test

```{r}
accuracy = function(actual, predicted) {
  mean(actual == predicted)
}
```

```{r}
accuracy(actual = y_default_test,
         predicted = knn(train = X_default_train, 
                         test = X_default_test, 
                         cl = y_default_train, k = 5))
```

```{r}
accuracy(actual = y_default_test,
         predicted = knn(train = scale(X_default_train), 
                         test = scale(X_default_test), 
                         cl = y_default_train, k = 5))
```

- TODO: normalization
- TODO: `scale()`
- TODO: compare results


- TODO: seq_along
- TODO: change error to acc

```{r}
set.seed(42)
k_to_try = 100
acc_k = rep(0, k_to_try)
for(i in 1:k_to_try) {
  pred = knn(train = scale(X_default_train), 
             test = scale(X_default_test), 
             cl = y_default_train, 
             k = i)
  acc_k[i] = accuracy(y_default_test, pred)
}
max(acc_k)

```

```{r}
seq_along(1:k_to_try)
```

- TODO: make plot nicer

```{r, fig.height = 5, fig.width = 10}
# plot accuracy vs choice of k
plot(acc_k, type = "b", col = "dodgerblue", cex = 1, pch = 20, 
     xlab = "k, number of neighbors", ylab = "classification accuracy",
     main = "Accuracy vs Neighbors")
# add lines indicating k with best accuracy
abline(v = which(acc_k == max(acc_k)), col = "darkorange", lwd = 1.5)
# add line for max accuracy seen
abline(h = max(acc_k), col = "grey", lty = 2)
# add line for prevalence in test set
abline(h = mean(y_default_test == "No"), col = "grey", lty = 2)
```

```{r}
max(which(acc_k == max(acc_k)))
```

- TODO: if ties, pick least flexible, highest k model, lowest chance of overfitting
- TODO: eventually "averaging" over entire dataset, acc approaching prevelence

```{r}
mean(y_default_test == "No")
```












- TODO: iris data
    - previous test-train split
    - X Y split



- TODO: how to obtain probabilites
- TODO: prob is sort of weird. given for BEST class only.


- TODO: plot acc vs k
- TODO: seq_along



- TODO: curse of dimensionality


## Regression


- TODO: regression data
- TODO: boston
- TODO: plot with fitting for various k, single predictor. back to boston. see old.


