<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>R for Statistical Learning</title>
  <meta name="description" content="R for Statistical Learning">
  <meta name="generator" content="bookdown 0.3.14 and GitBook 2.6.7">

  <meta property="og:title" content="R for Statistical Learning" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="http://daviddalpiaz.github.io/r4sl/" />
  
  
  <meta name="github-repo" content="daviddalpiaz/r4sl" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="R for Statistical Learning" />
  
  
  

<meta name="author" content="David Dalpiaz">


<meta name="date" content="2017-03-20">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  <link rel="shortcut icon" href="favicon.ico" type="image/x-icon">
<link rel="prev" href="simulating-the-biasvariance-tradeoff.html">
<link rel="next" href="logistic-regression.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">R for Statistical Learning</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction</a><ul>
<li class="chapter" data-level="0.1" data-path="index.html"><a href="index.html#about-this-book"><i class="fa fa-check"></i><b>0.1</b> About This Book</a></li>
<li class="chapter" data-level="0.2" data-path="index.html"><a href="index.html#caveat-emptor"><i class="fa fa-check"></i><b>0.2</b> Caveat Emptor</a></li>
<li class="chapter" data-level="0.3" data-path="index.html"><a href="index.html#conventions"><i class="fa fa-check"></i><b>0.3</b> Conventions</a></li>
<li class="chapter" data-level="0.4" data-path="index.html"><a href="index.html#acknowledgements"><i class="fa fa-check"></i><b>0.4</b> Acknowledgements</a></li>
<li class="chapter" data-level="0.5" data-path="index.html"><a href="index.html#license"><i class="fa fa-check"></i><b>0.5</b> License</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="probability-review.html"><a href="probability-review.html"><i class="fa fa-check"></i><b>1</b> Probability Review</a><ul>
<li class="chapter" data-level="1.1" data-path="probability-review.html"><a href="probability-review.html#probability-models"><i class="fa fa-check"></i><b>1.1</b> Probability Models</a></li>
<li class="chapter" data-level="1.2" data-path="probability-review.html"><a href="probability-review.html#probability-axioms"><i class="fa fa-check"></i><b>1.2</b> Probability Axioms</a></li>
<li class="chapter" data-level="1.3" data-path="probability-review.html"><a href="probability-review.html#probability-rules"><i class="fa fa-check"></i><b>1.3</b> Probability Rules</a></li>
<li class="chapter" data-level="1.4" data-path="probability-review.html"><a href="probability-review.html#random-variables"><i class="fa fa-check"></i><b>1.4</b> Random Variables</a><ul>
<li class="chapter" data-level="1.4.1" data-path="probability-review.html"><a href="probability-review.html#distributions"><i class="fa fa-check"></i><b>1.4.1</b> Distributions</a></li>
<li class="chapter" data-level="1.4.2" data-path="probability-review.html"><a href="probability-review.html#discrete-random-variables"><i class="fa fa-check"></i><b>1.4.2</b> Discrete Random Variables</a></li>
<li class="chapter" data-level="1.4.3" data-path="probability-review.html"><a href="probability-review.html#continuous-random-variables"><i class="fa fa-check"></i><b>1.4.3</b> Continuous Random Variables</a></li>
<li class="chapter" data-level="1.4.4" data-path="probability-review.html"><a href="probability-review.html#several-random-variables"><i class="fa fa-check"></i><b>1.4.4</b> Several Random Variables</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="probability-review.html"><a href="probability-review.html#expectations"><i class="fa fa-check"></i><b>1.5</b> Expectations</a></li>
<li class="chapter" data-level="1.6" data-path="probability-review.html"><a href="probability-review.html#likelihood"><i class="fa fa-check"></i><b>1.6</b> Likelihood</a></li>
<li class="chapter" data-level="1.7" data-path="probability-review.html"><a href="probability-review.html#references"><i class="fa fa-check"></i><b>1.7</b> References</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="introduction-to-r.html"><a href="introduction-to-r.html"><i class="fa fa-check"></i><b>2</b> Introduction to <code>R</code></a><ul>
<li class="chapter" data-level="2.1" data-path="introduction-to-r.html"><a href="introduction-to-r.html#getting-started"><i class="fa fa-check"></i><b>2.1</b> Getting Started</a></li>
<li class="chapter" data-level="2.2" data-path="introduction-to-r.html"><a href="introduction-to-r.html#basic-calculations"><i class="fa fa-check"></i><b>2.2</b> Basic Calculations</a></li>
<li class="chapter" data-level="2.3" data-path="introduction-to-r.html"><a href="introduction-to-r.html#getting-help"><i class="fa fa-check"></i><b>2.3</b> Getting Help</a></li>
<li class="chapter" data-level="2.4" data-path="introduction-to-r.html"><a href="introduction-to-r.html#installing-packages"><i class="fa fa-check"></i><b>2.4</b> Installing Packages</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="data-and-programming.html"><a href="data-and-programming.html"><i class="fa fa-check"></i><b>3</b> Data and Programming</a><ul>
<li class="chapter" data-level="3.1" data-path="data-and-programming.html"><a href="data-and-programming.html#data-types"><i class="fa fa-check"></i><b>3.1</b> Data Types</a></li>
<li class="chapter" data-level="3.2" data-path="data-and-programming.html"><a href="data-and-programming.html#data-structures"><i class="fa fa-check"></i><b>3.2</b> Data Structures</a><ul>
<li class="chapter" data-level="3.2.1" data-path="data-and-programming.html"><a href="data-and-programming.html#vectors"><i class="fa fa-check"></i><b>3.2.1</b> Vectors</a></li>
<li class="chapter" data-level="3.2.2" data-path="data-and-programming.html"><a href="data-and-programming.html#vectorization"><i class="fa fa-check"></i><b>3.2.2</b> Vectorization</a></li>
<li class="chapter" data-level="3.2.3" data-path="data-and-programming.html"><a href="data-and-programming.html#logical-operators"><i class="fa fa-check"></i><b>3.2.3</b> Logical Operators</a></li>
<li class="chapter" data-level="3.2.4" data-path="data-and-programming.html"><a href="data-and-programming.html#more-vectorization"><i class="fa fa-check"></i><b>3.2.4</b> More Vectorization</a></li>
<li class="chapter" data-level="3.2.5" data-path="data-and-programming.html"><a href="data-and-programming.html#matrices"><i class="fa fa-check"></i><b>3.2.5</b> Matrices</a></li>
<li class="chapter" data-level="3.2.6" data-path="data-and-programming.html"><a href="data-and-programming.html#lists"><i class="fa fa-check"></i><b>3.2.6</b> Lists</a></li>
<li class="chapter" data-level="3.2.7" data-path="data-and-programming.html"><a href="data-and-programming.html#data-frames"><i class="fa fa-check"></i><b>3.2.7</b> Data Frames</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="data-and-programming.html"><a href="data-and-programming.html#programming-basics"><i class="fa fa-check"></i><b>3.3</b> Programming Basics</a><ul>
<li class="chapter" data-level="3.3.1" data-path="data-and-programming.html"><a href="data-and-programming.html#control-flow"><i class="fa fa-check"></i><b>3.3.1</b> Control Flow</a></li>
<li class="chapter" data-level="3.3.2" data-path="data-and-programming.html"><a href="data-and-programming.html#functions"><i class="fa fa-check"></i><b>3.3.2</b> Functions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="summarizing-data.html"><a href="summarizing-data.html"><i class="fa fa-check"></i><b>4</b> Summarizing Data</a><ul>
<li class="chapter" data-level="4.1" data-path="summarizing-data.html"><a href="summarizing-data.html#summary-statistics"><i class="fa fa-check"></i><b>4.1</b> Summary Statistics</a><ul>
<li class="chapter" data-level="" data-path="summarizing-data.html"><a href="summarizing-data.html#central-tendency"><i class="fa fa-check"></i>Central Tendency</a></li>
<li class="chapter" data-level="" data-path="summarizing-data.html"><a href="summarizing-data.html#spread"><i class="fa fa-check"></i>Spread</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="summarizing-data.html"><a href="summarizing-data.html#plotting"><i class="fa fa-check"></i><b>4.2</b> Plotting</a><ul>
<li class="chapter" data-level="4.2.1" data-path="summarizing-data.html"><a href="summarizing-data.html#histograms"><i class="fa fa-check"></i><b>4.2.1</b> Histograms</a></li>
<li class="chapter" data-level="4.2.2" data-path="summarizing-data.html"><a href="summarizing-data.html#barplots"><i class="fa fa-check"></i><b>4.2.2</b> Barplots</a></li>
<li class="chapter" data-level="4.2.3" data-path="summarizing-data.html"><a href="summarizing-data.html#boxplots"><i class="fa fa-check"></i><b>4.2.3</b> Boxplots</a></li>
<li class="chapter" data-level="4.2.4" data-path="summarizing-data.html"><a href="summarizing-data.html#scatterplots"><i class="fa fa-check"></i><b>4.2.4</b> Scatterplots</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="r-resources.html"><a href="r-resources.html"><i class="fa fa-check"></i><b>5</b> <code>R</code> Resources</a><ul>
<li class="chapter" data-level="5.1" data-path="r-resources.html"><a href="r-resources.html#beginner-tutorials-and-references"><i class="fa fa-check"></i><b>5.1</b> Beginner Tutorials and References</a></li>
<li class="chapter" data-level="5.2" data-path="r-resources.html"><a href="r-resources.html#intermediate-references"><i class="fa fa-check"></i><b>5.2</b> Intermediate References</a></li>
<li class="chapter" data-level="5.3" data-path="r-resources.html"><a href="r-resources.html#advanced-references"><i class="fa fa-check"></i><b>5.3</b> Advanced References</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="probability-in-r.html"><a href="probability-in-r.html"><i class="fa fa-check"></i><b>6</b> Probability in <code>R</code></a><ul>
<li class="chapter" data-level="6.1" data-path="probability-in-r.html"><a href="probability-in-r.html#distributions-1"><i class="fa fa-check"></i><b>6.1</b> Distributions</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="hypothesis-tests-in-r.html"><a href="hypothesis-tests-in-r.html"><i class="fa fa-check"></i><b>7</b> Hypothesis Tests in <code>R</code></a><ul>
<li class="chapter" data-level="7.0.1" data-path="hypothesis-tests-in-r.html"><a href="hypothesis-tests-in-r.html#one-sample-t-test-review"><i class="fa fa-check"></i><b>7.0.1</b> One Sample t-Test: Review</a></li>
<li class="chapter" data-level="7.0.2" data-path="hypothesis-tests-in-r.html"><a href="hypothesis-tests-in-r.html#one-sample-t-test-example"><i class="fa fa-check"></i><b>7.0.2</b> One Sample t-Test: Example</a></li>
<li class="chapter" data-level="7.0.3" data-path="hypothesis-tests-in-r.html"><a href="hypothesis-tests-in-r.html#two-sample-t-test-review"><i class="fa fa-check"></i><b>7.0.3</b> Two Sample t-Test: Review</a></li>
<li class="chapter" data-level="7.0.4" data-path="hypothesis-tests-in-r.html"><a href="hypothesis-tests-in-r.html#two-sample-t-test-example"><i class="fa fa-check"></i><b>7.0.4</b> Two Sample t-Test: Example</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="simulation.html"><a href="simulation.html"><i class="fa fa-check"></i><b>8</b> Simulation</a><ul>
<li class="chapter" data-level="8.0.1" data-path="simulation.html"><a href="simulation.html#paired-differences"><i class="fa fa-check"></i><b>8.0.1</b> Paired Differences</a></li>
<li class="chapter" data-level="8.0.2" data-path="simulation.html"><a href="simulation.html#distribution-of-a-sample-mean"><i class="fa fa-check"></i><b>8.0.2</b> Distribution of a Sample Mean</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="rstudio-and-rmarkdown.html"><a href="rstudio-and-rmarkdown.html"><i class="fa fa-check"></i><b>9</b> RStudio and RMarkdown</a><ul>
<li class="chapter" data-level="9.1" data-path="rstudio-and-rmarkdown.html"><a href="rstudio-and-rmarkdown.html#template"><i class="fa fa-check"></i><b>9.1</b> Template</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="regression-basics-in-r.html"><a href="regression-basics-in-r.html"><i class="fa fa-check"></i><b>10</b> Regression Basics in <code>R</code></a><ul>
<li class="chapter" data-level="10.1" data-path="regression-basics-in-r.html"><a href="regression-basics-in-r.html#visualization-for-regression"><i class="fa fa-check"></i><b>10.1</b> Visualization for Regression</a></li>
<li class="chapter" data-level="10.2" data-path="regression-basics-in-r.html"><a href="regression-basics-in-r.html#the-lm-function"><i class="fa fa-check"></i><b>10.2</b> The <code>lm()</code> Function</a></li>
<li class="chapter" data-level="10.3" data-path="regression-basics-in-r.html"><a href="regression-basics-in-r.html#hypothesis-testing"><i class="fa fa-check"></i><b>10.3</b> Hypothesis Testing</a></li>
<li class="chapter" data-level="10.4" data-path="regression-basics-in-r.html"><a href="regression-basics-in-r.html#prediction"><i class="fa fa-check"></i><b>10.4</b> Prediction</a></li>
<li class="chapter" data-level="10.5" data-path="regression-basics-in-r.html"><a href="regression-basics-in-r.html#unusual-observations"><i class="fa fa-check"></i><b>10.5</b> Unusual Observations</a></li>
<li class="chapter" data-level="10.6" data-path="regression-basics-in-r.html"><a href="regression-basics-in-r.html#adding-complexity"><i class="fa fa-check"></i><b>10.6</b> Adding Complexity</a><ul>
<li class="chapter" data-level="10.6.1" data-path="regression-basics-in-r.html"><a href="regression-basics-in-r.html#interactions"><i class="fa fa-check"></i><b>10.6.1</b> Interactions</a></li>
<li class="chapter" data-level="10.6.2" data-path="regression-basics-in-r.html"><a href="regression-basics-in-r.html#polynomials"><i class="fa fa-check"></i><b>10.6.2</b> Polynomials</a></li>
<li class="chapter" data-level="10.6.3" data-path="regression-basics-in-r.html"><a href="regression-basics-in-r.html#transformations"><i class="fa fa-check"></i><b>10.6.3</b> Transformations</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="regression-for-statistical-learning.html"><a href="regression-for-statistical-learning.html"><i class="fa fa-check"></i><b>11</b> Regression for Statistical Learning</a><ul>
<li class="chapter" data-level="11.1" data-path="regression-for-statistical-learning.html"><a href="regression-for-statistical-learning.html#assesing-model-accuracy"><i class="fa fa-check"></i><b>11.1</b> Assesing Model Accuracy</a></li>
<li class="chapter" data-level="11.2" data-path="regression-for-statistical-learning.html"><a href="regression-for-statistical-learning.html#model-complexity"><i class="fa fa-check"></i><b>11.2</b> Model Complexity</a></li>
<li class="chapter" data-level="11.3" data-path="regression-for-statistical-learning.html"><a href="regression-for-statistical-learning.html#test-train-split"><i class="fa fa-check"></i><b>11.3</b> Test-Train Split</a></li>
<li class="chapter" data-level="11.4" data-path="regression-for-statistical-learning.html"><a href="regression-for-statistical-learning.html#adding-flexibility-to-linear-models"><i class="fa fa-check"></i><b>11.4</b> Adding Flexibility to Linear Models</a></li>
<li class="chapter" data-level="11.5" data-path="regression-for-statistical-learning.html"><a href="regression-for-statistical-learning.html#choosing-a-model"><i class="fa fa-check"></i><b>11.5</b> Choosing a Model</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="simulating-the-biasvariance-tradeoff.html"><a href="simulating-the-biasvariance-tradeoff.html"><i class="fa fa-check"></i><b>12</b> Simulating the Bias–Variance Tradeoff</a><ul>
<li class="chapter" data-level="12.1" data-path="simulating-the-biasvariance-tradeoff.html"><a href="simulating-the-biasvariance-tradeoff.html#bias-variance-decomposition"><i class="fa fa-check"></i><b>12.1</b> Bias-Variance Decomposition</a></li>
<li class="chapter" data-level="12.2" data-path="simulating-the-biasvariance-tradeoff.html"><a href="simulating-the-biasvariance-tradeoff.html#simulation-1"><i class="fa fa-check"></i><b>12.2</b> Simulation</a></li>
<li class="chapter" data-level="12.3" data-path="simulating-the-biasvariance-tradeoff.html"><a href="simulating-the-biasvariance-tradeoff.html#bias-variance-tradeoff"><i class="fa fa-check"></i><b>12.3</b> Bias-Variance Tradeoff</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="classification.html"><a href="classification.html"><i class="fa fa-check"></i><b>13</b> Classification</a><ul>
<li class="chapter" data-level="13.1" data-path="classification.html"><a href="classification.html#visualization-for-classification"><i class="fa fa-check"></i><b>13.1</b> Visualization for Classification</a></li>
<li class="chapter" data-level="13.2" data-path="classification.html"><a href="classification.html#a-simple-classifier"><i class="fa fa-check"></i><b>13.2</b> A Simple Classifier</a></li>
<li class="chapter" data-level="13.3" data-path="classification.html"><a href="classification.html#metrics-for-classification"><i class="fa fa-check"></i><b>13.3</b> Metrics for Classification</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>14</b> Logistic Regression</a><ul>
<li class="chapter" data-level="14.1" data-path="logistic-regression.html"><a href="logistic-regression.html#linear-regression"><i class="fa fa-check"></i><b>14.1</b> Linear Regression</a></li>
<li class="chapter" data-level="14.2" data-path="logistic-regression.html"><a href="logistic-regression.html#bayes-classifier"><i class="fa fa-check"></i><b>14.2</b> Bayes Classifier</a></li>
<li class="chapter" data-level="14.3" data-path="logistic-regression.html"><a href="logistic-regression.html#logistic-regression-with-glm"><i class="fa fa-check"></i><b>14.3</b> Logistic Regression with <code>glm()</code></a></li>
<li class="chapter" data-level="14.4" data-path="logistic-regression.html"><a href="logistic-regression.html#roc-curves"><i class="fa fa-check"></i><b>14.4</b> ROC Curves</a></li>
<li class="chapter" data-level="14.5" data-path="logistic-regression.html"><a href="logistic-regression.html#multinomial-logistic-regression"><i class="fa fa-check"></i><b>14.5</b> Multinomial Logistic Regression</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="generative-models.html"><a href="generative-models.html"><i class="fa fa-check"></i><b>15</b> Generative Models</a><ul>
<li class="chapter" data-level="15.1" data-path="generative-models.html"><a href="generative-models.html#linear-discriminant-analysis"><i class="fa fa-check"></i><b>15.1</b> Linear Discriminant Analysis</a></li>
<li class="chapter" data-level="15.2" data-path="generative-models.html"><a href="generative-models.html#quadratic-discriminant-analysis"><i class="fa fa-check"></i><b>15.2</b> Quadratic Discriminant Analysis</a></li>
<li class="chapter" data-level="15.3" data-path="generative-models.html"><a href="generative-models.html#naive-bayes"><i class="fa fa-check"></i><b>15.3</b> Naive Bayes</a></li>
<li class="chapter" data-level="15.4" data-path="generative-models.html"><a href="generative-models.html#discrete-inputs"><i class="fa fa-check"></i><b>15.4</b> Discrete Inputs</a></li>
<li class="chapter" data-level="15.5" data-path="generative-models.html"><a href="generative-models.html#rmarkdown"><i class="fa fa-check"></i><b>15.5</b> RMarkdown</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="k-nearest-neighbors.html"><a href="k-nearest-neighbors.html"><i class="fa fa-check"></i><b>16</b> k-Nearest Neighbors</a><ul>
<li class="chapter" data-level="16.1" data-path="k-nearest-neighbors.html"><a href="k-nearest-neighbors.html#classification-1"><i class="fa fa-check"></i><b>16.1</b> Classification</a><ul>
<li class="chapter" data-level="16.1.1" data-path="k-nearest-neighbors.html"><a href="k-nearest-neighbors.html#default-data"><i class="fa fa-check"></i><b>16.1.1</b> Default Data</a></li>
<li class="chapter" data-level="16.1.2" data-path="k-nearest-neighbors.html"><a href="k-nearest-neighbors.html#iris-data"><i class="fa fa-check"></i><b>16.1.2</b> Iris Data</a></li>
</ul></li>
<li class="chapter" data-level="16.2" data-path="k-nearest-neighbors.html"><a href="k-nearest-neighbors.html#regression"><i class="fa fa-check"></i><b>16.2</b> Regression</a></li>
<li class="chapter" data-level="16.3" data-path="k-nearest-neighbors.html"><a href="k-nearest-neighbors.html#external-links"><i class="fa fa-check"></i><b>16.3</b> External Links</a></li>
<li class="chapter" data-level="16.4" data-path="k-nearest-neighbors.html"><a href="k-nearest-neighbors.html#rmarkdown-1"><i class="fa fa-check"></i><b>16.4</b> RMarkdown</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="resampling.html"><a href="resampling.html"><i class="fa fa-check"></i><b>17</b> Resampling</a><ul>
<li class="chapter" data-level="17.1" data-path="resampling.html"><a href="resampling.html#test-train-split-1"><i class="fa fa-check"></i><b>17.1</b> Test-Train Split</a></li>
<li class="chapter" data-level="17.2" data-path="resampling.html"><a href="resampling.html#cross-validation"><i class="fa fa-check"></i><b>17.2</b> Cross-Validation</a><ul>
<li class="chapter" data-level="17.2.1" data-path="resampling.html"><a href="resampling.html#method-specific"><i class="fa fa-check"></i><b>17.2.1</b> Method Specific</a></li>
<li class="chapter" data-level="17.2.2" data-path="resampling.html"><a href="resampling.html#manual-cross-validation"><i class="fa fa-check"></i><b>17.2.2</b> Manual Cross-Validation</a></li>
<li class="chapter" data-level="17.2.3" data-path="resampling.html"><a href="resampling.html#test-data"><i class="fa fa-check"></i><b>17.2.3</b> Test Data</a></li>
</ul></li>
<li class="chapter" data-level="17.3" data-path="resampling.html"><a href="resampling.html#bootstrap"><i class="fa fa-check"></i><b>17.3</b> Bootstrap</a></li>
<li class="chapter" data-level="17.4" data-path="resampling.html"><a href="resampling.html#external-links-1"><i class="fa fa-check"></i><b>17.4</b> External Links</a></li>
<li class="chapter" data-level="17.5" data-path="resampling.html"><a href="resampling.html#rmarkdown-2"><i class="fa fa-check"></i><b>17.5</b> RMarkdown</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="classification-overview.html"><a href="classification-overview.html"><i class="fa fa-check"></i><b>18</b> Classification Overview</a><ul>
<li class="chapter" data-level="" data-path="classification-overview.html"><a href="classification-overview.html#bayes-classifier-1"><i class="fa fa-check"></i>Bayes Classifier</a></li>
<li class="chapter" data-level="" data-path="classification-overview.html"><a href="classification-overview.html#the-bias-variance-tradeoff"><i class="fa fa-check"></i>The Bias-Variance Tradeoff</a></li>
<li class="chapter" data-level="" data-path="classification-overview.html"><a href="classification-overview.html#the-test-train-split"><i class="fa fa-check"></i>The Test-Train Split</a></li>
<li class="chapter" data-level="" data-path="classification-overview.html"><a href="classification-overview.html#classification-methods"><i class="fa fa-check"></i>Classification Methods</a></li>
<li class="chapter" data-level="" data-path="classification-overview.html"><a href="classification-overview.html#discriminative-versus-generative-methods"><i class="fa fa-check"></i>Discriminative versus Generative Methods</a></li>
<li class="chapter" data-level="" data-path="classification-overview.html"><a href="classification-overview.html#parametric-and-non-parametric-methods"><i class="fa fa-check"></i>Parametric and Non-Parametric Methods</a></li>
<li class="chapter" data-level="" data-path="classification-overview.html"><a href="classification-overview.html#tuning-parameters"><i class="fa fa-check"></i>Tuning Parameters</a></li>
<li class="chapter" data-level="" data-path="classification-overview.html"><a href="classification-overview.html#cross-validation-1"><i class="fa fa-check"></i>Cross-Validation</a></li>
<li class="chapter" data-level="" data-path="classification-overview.html"><a href="classification-overview.html#curse-of-dimensionality"><i class="fa fa-check"></i>Curse of Dimensionality</a></li>
<li class="chapter" data-level="" data-path="classification-overview.html"><a href="classification-overview.html#no-free-lunch-theorem"><i class="fa fa-check"></i>No-Free-Lunch Theorem</a></li>
<li class="chapter" data-level="18.1" data-path="classification-overview.html"><a href="classification-overview.html#external-links-2"><i class="fa fa-check"></i><b>18.1</b> External Links</a></li>
<li class="chapter" data-level="18.2" data-path="classification-overview.html"><a href="classification-overview.html#rmarkdown-3"><i class="fa fa-check"></i><b>18.2</b> RMarkdown</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="the-caret-package.html"><a href="the-caret-package.html"><i class="fa fa-check"></i><b>19</b> The <code>caret</code> Package</a><ul>
<li class="chapter" data-level="19.1" data-path="the-caret-package.html"><a href="the-caret-package.html#external-links-3"><i class="fa fa-check"></i><b>19.1</b> External Links</a></li>
<li class="chapter" data-level="19.2" data-path="the-caret-package.html"><a href="the-caret-package.html#rmarkdown-4"><i class="fa fa-check"></i><b>19.2</b> RMarkdown</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="subset-selection.html"><a href="subset-selection.html"><i class="fa fa-check"></i><b>20</b> Subset Selection</a><ul>
<li class="chapter" data-level="20.1" data-path="subset-selection.html"><a href="subset-selection.html#aic-bic-and-cp"><i class="fa fa-check"></i><b>20.1</b> AIC, BIC, and Cp</a><ul>
<li class="chapter" data-level="20.1.1" data-path="subset-selection.html"><a href="subset-selection.html#leaps-package"><i class="fa fa-check"></i><b>20.1.1</b> <code>leaps</code> Package</a></li>
<li class="chapter" data-level="20.1.2" data-path="subset-selection.html"><a href="subset-selection.html#best-subset"><i class="fa fa-check"></i><b>20.1.2</b> Best Subset</a></li>
<li class="chapter" data-level="20.1.3" data-path="subset-selection.html"><a href="subset-selection.html#stepwise-methods"><i class="fa fa-check"></i><b>20.1.3</b> Stepwise Methods</a></li>
</ul></li>
<li class="chapter" data-level="20.2" data-path="subset-selection.html"><a href="subset-selection.html#validated-rmse"><i class="fa fa-check"></i><b>20.2</b> Validated RMSE</a></li>
<li class="chapter" data-level="20.3" data-path="subset-selection.html"><a href="subset-selection.html#external-links-4"><i class="fa fa-check"></i><b>20.3</b> External Links</a></li>
<li class="chapter" data-level="20.4" data-path="subset-selection.html"><a href="subset-selection.html#rmarkdown-5"><i class="fa fa-check"></i><b>20.4</b> RMarkdown</a></li>
</ul></li>
<li class="chapter" data-level="21" data-path="shrinkage-methods.html"><a href="shrinkage-methods.html"><i class="fa fa-check"></i><b>21</b> Shrinkage Methods</a><ul>
<li class="chapter" data-level="21.1" data-path="shrinkage-methods.html"><a href="shrinkage-methods.html#ridge-regression"><i class="fa fa-check"></i><b>21.1</b> Ridge Regression</a></li>
<li class="chapter" data-level="21.2" data-path="shrinkage-methods.html"><a href="shrinkage-methods.html#lasso"><i class="fa fa-check"></i><b>21.2</b> Lasso</a></li>
<li class="chapter" data-level="21.3" data-path="shrinkage-methods.html"><a href="shrinkage-methods.html#broom"><i class="fa fa-check"></i><b>21.3</b> <code>broom</code></a></li>
<li class="chapter" data-level="21.4" data-path="shrinkage-methods.html"><a href="shrinkage-methods.html#simulation-study-p-n"><i class="fa fa-check"></i><b>21.4</b> Simulation Study, p &gt; n</a></li>
<li class="chapter" data-level="21.5" data-path="shrinkage-methods.html"><a href="shrinkage-methods.html#external-links-5"><i class="fa fa-check"></i><b>21.5</b> External Links</a></li>
<li class="chapter" data-level="21.6" data-path="shrinkage-methods.html"><a href="shrinkage-methods.html#rmarkdown-6"><i class="fa fa-check"></i><b>21.6</b> RMarkdown</a></li>
</ul></li>
<li class="chapter" data-level="22" data-path="elastic-net.html"><a href="elastic-net.html"><i class="fa fa-check"></i><b>22</b> Elastic Net</a><ul>
<li class="chapter" data-level="22.1" data-path="elastic-net.html"><a href="elastic-net.html#hitters-data"><i class="fa fa-check"></i><b>22.1</b> Hitters Data</a></li>
<li class="chapter" data-level="22.2" data-path="elastic-net.html"><a href="elastic-net.html#elastic-net-for-regression"><i class="fa fa-check"></i><b>22.2</b> Elastic Net for Regression</a></li>
<li class="chapter" data-level="22.3" data-path="elastic-net.html"><a href="elastic-net.html#elastic-net-for-classification"><i class="fa fa-check"></i><b>22.3</b> Elastic Net for Classification</a></li>
<li class="chapter" data-level="22.4" data-path="elastic-net.html"><a href="elastic-net.html#external-links-6"><i class="fa fa-check"></i><b>22.4</b> External Links</a></li>
<li class="chapter" data-level="22.5" data-path="elastic-net.html"><a href="elastic-net.html#rmarkdown-7"><i class="fa fa-check"></i><b>22.5</b> RMarkdown</a></li>
</ul></li>
<li class="chapter" data-level="23" data-path="regularized-discriminant-analysis.html"><a href="regularized-discriminant-analysis.html"><i class="fa fa-check"></i><b>23</b> Regularized Discriminant Analysis</a><ul>
<li class="chapter" data-level="23.1" data-path="regularized-discriminant-analysis.html"><a href="regularized-discriminant-analysis.html#sonar-data"><i class="fa fa-check"></i><b>23.1</b> Sonar Data</a></li>
<li class="chapter" data-level="23.2" data-path="regularized-discriminant-analysis.html"><a href="regularized-discriminant-analysis.html#rda"><i class="fa fa-check"></i><b>23.2</b> RDA</a></li>
<li class="chapter" data-level="23.3" data-path="regularized-discriminant-analysis.html"><a href="regularized-discriminant-analysis.html#rda-with-grid-search"><i class="fa fa-check"></i><b>23.3</b> RDA with Grid Search</a></li>
<li class="chapter" data-level="23.4" data-path="regularized-discriminant-analysis.html"><a href="regularized-discriminant-analysis.html#rda-with-random-search-search"><i class="fa fa-check"></i><b>23.4</b> RDA with Random Search Search</a></li>
<li class="chapter" data-level="23.5" data-path="regularized-discriminant-analysis.html"><a href="regularized-discriminant-analysis.html#comparison-to-elastic-net"><i class="fa fa-check"></i><b>23.5</b> Comparison to Elastic Net</a></li>
<li class="chapter" data-level="23.6" data-path="regularized-discriminant-analysis.html"><a href="regularized-discriminant-analysis.html#results"><i class="fa fa-check"></i><b>23.6</b> Results</a></li>
<li class="chapter" data-level="23.7" data-path="regularized-discriminant-analysis.html"><a href="regularized-discriminant-analysis.html#external-links-7"><i class="fa fa-check"></i><b>23.7</b> External Links</a></li>
<li class="chapter" data-level="23.8" data-path="regularized-discriminant-analysis.html"><a href="regularized-discriminant-analysis.html#rmarkdown-8"><i class="fa fa-check"></i><b>23.8</b> RMarkdown</a></li>
</ul></li>
<li class="chapter" data-level="24" data-path="non-linear-models.html"><a href="non-linear-models.html"><i class="fa fa-check"></i><b>24</b> Non-Linear Models</a><ul>
<li class="chapter" data-level="24.1" data-path="non-linear-models.html"><a href="non-linear-models.html#polynomial-regression"><i class="fa fa-check"></i><b>24.1</b> Polynomial Regression</a><ul>
<li class="chapter" data-level="24.1.1" data-path="non-linear-models.html"><a href="non-linear-models.html#anova"><i class="fa fa-check"></i><b>24.1.1</b> ANOVA</a></li>
</ul></li>
<li class="chapter" data-level="24.2" data-path="non-linear-models.html"><a href="non-linear-models.html#logistic-regression-polynomial-terms"><i class="fa fa-check"></i><b>24.2</b> Logistic Regression, Polynomial Terms</a></li>
<li class="chapter" data-level="24.3" data-path="non-linear-models.html"><a href="non-linear-models.html#step-functions"><i class="fa fa-check"></i><b>24.3</b> Step Functions</a><ul>
<li class="chapter" data-level="24.3.1" data-path="non-linear-models.html"><a href="non-linear-models.html#smoothing-splines"><i class="fa fa-check"></i><b>24.3.1</b> Smoothing Splines</a></li>
</ul></li>
<li class="chapter" data-level="24.4" data-path="non-linear-models.html"><a href="non-linear-models.html#local-regression"><i class="fa fa-check"></i><b>24.4</b> Local Regression</a></li>
<li class="chapter" data-level="24.5" data-path="non-linear-models.html"><a href="non-linear-models.html#generalized-additive-models-gams"><i class="fa fa-check"></i><b>24.5</b> Generalized Additive Models (GAMs)</a><ul>
<li class="chapter" data-level="24.5.1" data-path="non-linear-models.html"><a href="non-linear-models.html#gams-in-caret"><i class="fa fa-check"></i><b>24.5.1</b> GAMs in <code>caret</code></a></li>
</ul></li>
<li class="chapter" data-level="24.6" data-path="non-linear-models.html"><a href="non-linear-models.html#external-links-8"><i class="fa fa-check"></i><b>24.6</b> External Links</a></li>
<li class="chapter" data-level="24.7" data-path="non-linear-models.html"><a href="non-linear-models.html#rmarkdown-9"><i class="fa fa-check"></i><b>24.7</b> RMarkdown</a></li>
</ul></li>
<li class="chapter" data-level="25" data-path="trees.html"><a href="trees.html"><i class="fa fa-check"></i><b>25</b> Trees</a><ul>
<li class="chapter" data-level="25.1" data-path="trees.html"><a href="trees.html#classification-trees"><i class="fa fa-check"></i><b>25.1</b> Classification Trees</a></li>
<li class="chapter" data-level="25.2" data-path="trees.html"><a href="trees.html#regression-trees"><i class="fa fa-check"></i><b>25.2</b> Regression Trees</a></li>
<li class="chapter" data-level="25.3" data-path="trees.html"><a href="trees.html#rpart-package"><i class="fa fa-check"></i><b>25.3</b> <code>rpart</code> Package</a></li>
<li class="chapter" data-level="25.4" data-path="trees.html"><a href="trees.html#external-links-9"><i class="fa fa-check"></i><b>25.4</b> External Links</a></li>
<li class="chapter" data-level="25.5" data-path="trees.html"><a href="trees.html#rmarkdown-10"><i class="fa fa-check"></i><b>25.5</b> RMarkdown</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/daviddalpiaz/r4sl" target="blank">&copy; 2017 David Dalpiaz</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">R for Statistical Learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="classification" class="section level1">
<h1><span class="header-section-number">Chapter 13</span> Classification</h1>
<p><strong>Classification</strong> is a form of <strong>supervised learning</strong> where the response variable is categorical, as opposed to numeric for regression. <em>Our goal is to find a rule, algorithm, or function which takes as input a feature vector, and outputs a category which is the true category as often as possible.</em></p>
<div class="figure">
<img src="images/classification.png" alt="" />

</div>
<p>That is, the classifier <span class="math inline">\(\hat{C}\)</span> returns the predicted category <span class="math inline">\(\hat{y}\)</span>.</p>
<p><span class="math display">\[
\hat{y}_i = \hat{C}(\bf x_i)
\]</span></p>
<p>To build our first classifier, we will use the <code>Default</code> dataset from the <code>ISLR</code> package.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(ISLR)
<span class="kw">library</span>(tibble)
<span class="kw">as_tibble</span>(Default)</code></pre></div>
<pre><code>## # A tibble: 10,000 × 4
##    default student   balance    income
##     &lt;fctr&gt;  &lt;fctr&gt;     &lt;dbl&gt;     &lt;dbl&gt;
## 1       No      No  729.5265 44361.625
## 2       No     Yes  817.1804 12106.135
## 3       No      No 1073.5492 31767.139
## 4       No      No  529.2506 35704.494
## 5       No      No  785.6559 38463.496
## 6       No     Yes  919.5885  7491.559
## 7       No      No  825.5133 24905.227
## 8       No     Yes  808.6675 17600.451
## 9       No      No 1161.0579 37468.529
## 10      No      No    0.0000 29275.268
## # ... with 9,990 more rows</code></pre>
<p>Our goal is to properly classify individuals as defaulters based on student status, credit card balance, and income. Be aware that the response <code>default</code> is a factor, as is the predictor <code>student</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">is.factor</span>(Default$default)</code></pre></div>
<pre><code>## [1] TRUE</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">is.factor</span>(Default$student)</code></pre></div>
<pre><code>## [1] TRUE</code></pre>
<p>As we did with regression, we test-train split our data. In this case, using 50% for each.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">42</span>)
train_index =<span class="st"> </span><span class="kw">sample</span>(<span class="kw">nrow</span>(Default), <span class="dv">5000</span>)
train_default =<span class="st"> </span>Default[train_index, ]
test_default =<span class="st"> </span>Default[-train_index, ]</code></pre></div>
<div id="visualization-for-classification" class="section level2">
<h2><span class="header-section-number">13.1</span> Visualization for Classification</h2>
<p>Often, some simple visualizations can suggest simple classification rules. To quickly create some useful visualizations, we use the <code>featurePlot()</code> function from the <code>caret()</code> package.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(caret)</code></pre></div>
<p>A density plot can often suggest a simple split based on a numeric predictor. Essentially this plot graphs a density estimate</p>
<p><span class="math display">\[
f_{X_i}(x_i \mid y = k)
\]</span></p>
<p>for each numeric predictor <span class="math inline">\(x_i\)</span> and each category <span class="math inline">\(k\)</span> of the response <span class="math inline">\(y\)</span>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">featurePlot</span>(<span class="dt">x =</span> train_default[, <span class="kw">c</span>(<span class="st">&quot;balance&quot;</span>, <span class="st">&quot;income&quot;</span>)], 
            <span class="dt">y =</span> train_default$default,
            <span class="dt">plot =</span> <span class="st">&quot;density&quot;</span>, 
            <span class="dt">scales =</span> <span class="kw">list</span>(<span class="dt">x =</span> <span class="kw">list</span>(<span class="dt">relation =</span> <span class="st">&quot;free&quot;</span>), 
                          <span class="dt">y =</span> <span class="kw">list</span>(<span class="dt">relation =</span> <span class="st">&quot;free&quot;</span>)), 
            <span class="dt">adjust =</span> <span class="fl">1.5</span>, 
            <span class="dt">pch =</span> <span class="st">&quot;|&quot;</span>, 
            <span class="dt">layout =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">1</span>), 
            <span class="dt">auto.key =</span> <span class="kw">list</span>(<span class="dt">columns =</span> <span class="dv">2</span>))</code></pre></div>
<p><img src="07-classification_files/figure-html/unnamed-chunk-5-1.png" width="960" /></p>
<p>Some notes about the arguments to this function:</p>
<ul>
<li><code>x</code> is a data frame containing only <strong>numeric predictors</strong>. It would be nonsensical to estimate a density for a categorical predictor.</li>
<li><code>y</code> is the response variable. It needs to be a factor variable. If coded as <code>0</code> and <code>1</code>, you will need to coerce to factor for plotting.</li>
<li><code>plot</code> specifies the type of plot, here <code>density</code>.</li>
<li><code>scales</code> defines the scale of the axes for each plot. By default, the axis of each plot would be the same, which often is not useful, so the arguments here, a different axis for each plot, will almost always be used.</li>
<li><code>adjust</code> specifies the amount of smoothing used for the density estimate.</li>
<li><code>pch</code> specifies the <strong>p</strong>lot <strong>ch</strong>aracter used for the bottom of the plot.</li>
<li><code>layout</code> places the individual plots into rows and columns. For some odd reason, it is given as (col, row).</li>
<li><code>auto.key</code> defines the key at the top of the plot. The number of columns should be the number of categories.</li>
</ul>
<p>It seems that the income variable by itself is not particularly useful. However, there seems to be a big difference in default status at a <code>balance</code> of about 1400. We will use this information shortly.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">featurePlot</span>(<span class="dt">x =</span> train_default[, <span class="kw">c</span>(<span class="st">&quot;balance&quot;</span>, <span class="st">&quot;income&quot;</span>)], 
            <span class="dt">y =</span> train_default$student,
            <span class="dt">plot =</span> <span class="st">&quot;density&quot;</span>, 
            <span class="dt">scales =</span> <span class="kw">list</span>(<span class="dt">x =</span> <span class="kw">list</span>(<span class="dt">relation =</span> <span class="st">&quot;free&quot;</span>), 
                          <span class="dt">y =</span> <span class="kw">list</span>(<span class="dt">relation =</span> <span class="st">&quot;free&quot;</span>)), 
            <span class="dt">adjust =</span> <span class="fl">1.5</span>, 
            <span class="dt">pch =</span> <span class="st">&quot;|&quot;</span>, 
            <span class="dt">layout =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">1</span>), 
            <span class="dt">auto.key =</span> <span class="kw">list</span>(<span class="dt">columns =</span> <span class="dv">2</span>))</code></pre></div>
<p><img src="07-classification_files/figure-html/unnamed-chunk-6-1.png" width="960" /></p>
<p>Above, we create a similar plot, except with <code>student</code> as the response. We see that students often carry a slightly larger balance, and have far lower income. This will be useful to know when making more complicated classifiers.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">featurePlot</span>(<span class="dt">x =</span> train_default[, <span class="kw">c</span>(<span class="st">&quot;student&quot;</span>, <span class="st">&quot;balance&quot;</span>, <span class="st">&quot;income&quot;</span>)], 
            <span class="dt">y =</span> train_default$default, 
            <span class="dt">plot =</span> <span class="st">&quot;pairs&quot;</span>,
            <span class="dt">auto.key =</span> <span class="kw">list</span>(<span class="dt">columns =</span> <span class="dv">2</span>))</code></pre></div>
<p><img src="07-classification_files/figure-html/unnamed-chunk-7-1.png" width="576" /></p>
<p>We can use <code>plot = &quot;pairs&quot;</code> to consider multiple variables at the same time. This plot reinforces using <code>balance</code> to create a classifier, and again shows that <code>income</code> seems not that useful.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(ellipse)
<span class="kw">featurePlot</span>(<span class="dt">x =</span> train_default[, <span class="kw">c</span>(<span class="st">&quot;balance&quot;</span>, <span class="st">&quot;income&quot;</span>)], 
            <span class="dt">y =</span> train_default$default, 
            <span class="dt">plot =</span> <span class="st">&quot;ellipse&quot;</span>,
            <span class="dt">auto.key =</span> <span class="kw">list</span>(<span class="dt">columns =</span> <span class="dv">2</span>))</code></pre></div>
<p><img src="07-classification_files/figure-html/unnamed-chunk-8-1.png" width="576" /></p>
<p>Similar to <code>pairs</code> is a plot of type <code>ellipse</code>, which requires the <code>ellipse</code> package. Here we only use numeric predictors, as essentially we are assuming multivariate normality. The ellipses mark points of equal density. This will be useful later when discussing LDA and QDA.</p>
</div>
<div id="a-simple-classifier" class="section level2">
<h2><span class="header-section-number">13.2</span> A Simple Classifier</h2>
<p>A very simple classifier is a rule based on a boundary <span class="math inline">\(b\)</span> for a particular input variable <span class="math inline">\(x\)</span>.</p>
<p><span class="math display">\[
\hat{C}(\bf x) = 
\begin{cases} 
      1 &amp; x &gt; b \\
      0 &amp; x \leq b 
\end{cases}
\]</span></p>
<p>Based on the first plot, we believe we can use <code>balance</code> to create a reasonable classifier. In particular,</p>
<p><span class="math display">\[
\hat{C}(\text{balance}) = 
\begin{cases} 
      \text{Yes} &amp; \text{balance} &gt; 1400 \\
      \text{No} &amp; \text{balance} \leq 1400 
   \end{cases}
\]</span></p>
<p>So we predict an individual is a defaulter if their <code>balance</code> is above 1400, and not a defaulter if the balance is 1400 or less.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">simple_class =<span class="st"> </span>function(x, boundary, <span class="dt">above =</span> <span class="dv">1</span>, <span class="dt">below =</span> <span class="dv">0</span>) {
  <span class="kw">ifelse</span>(x &gt;<span class="st"> </span>boundary, above, below)
}</code></pre></div>
<p>We write a simple <code>R</code> function that compares a variable to a boundary, then use it to make predictions on the train and test sets with our chosen variable and boundary.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">train_pred =<span class="st"> </span><span class="kw">simple_class</span>(<span class="dt">x =</span> train_default$balance, 
                          <span class="dt">boundary =</span> <span class="dv">1400</span>, <span class="dt">above =</span> <span class="st">&quot;Yes&quot;</span>, <span class="dt">below =</span> <span class="st">&quot;No&quot;</span>)
test_pred =<span class="st"> </span><span class="kw">simple_class</span>(<span class="dt">x =</span> test_default$balance, 
                         <span class="dt">boundary =</span> <span class="dv">1400</span>, <span class="dt">above =</span> <span class="st">&quot;Yes&quot;</span>, <span class="dt">below =</span> <span class="st">&quot;No&quot;</span>)
<span class="kw">head</span>(train_pred, <span class="dt">n =</span> <span class="dv">10</span>)</code></pre></div>
<pre><code>##  [1] &quot;No&quot;  &quot;Yes&quot; &quot;No&quot;  &quot;No&quot;  &quot;No&quot;  &quot;No&quot;  &quot;No&quot;  &quot;No&quot;  &quot;No&quot;  &quot;No&quot;</code></pre>
</div>
<div id="metrics-for-classification" class="section level2">
<h2><span class="header-section-number">13.3</span> Metrics for Classification</h2>
<p>In the classification setting, there are a large number of metrics to asses how well a classifier is performing.</p>
<p>One of the most obvious things to do is arrange predictions and true values in a cross table.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(<span class="dt">train_tab =</span> <span class="kw">table</span>(<span class="dt">predicted =</span> train_pred, <span class="dt">actual =</span> train_default$default))</code></pre></div>
<pre><code>##          actual
## predicted   No  Yes
##       No  4319   29
##       Yes  513  139</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(<span class="dt">test_tab =</span> <span class="kw">table</span>(<span class="dt">predicted =</span> test_pred, <span class="dt">actual =</span> test_default$default))</code></pre></div>
<pre><code>##          actual
## predicted   No  Yes
##       No  4361   23
##       Yes  474  142</code></pre>
<p>Often we give specific names to individual cells of these tables, and in the predictive setting, we would call this table a <a href="https://en.wikipedia.org/wiki/Confusion_matrix"><strong>confusion matrix</strong></a>. Be aware, that the placement of Actual and Predicted values affects the names of the cells, and often the matrix may be presented transposed.</p>
<p>In statistics, we label the errors Type I and Type II, but these are hard to remember. False Positive and False Negative are more descriptive, so we choose to use these.</p>
<div class="figure">
<img src="images/confusion.png" alt="" />

</div>
<p>The <code>confusionMatrix()</code> function from the <code>caret</code> package can be used to obtain a wealth of additional information, which we see output below for the test data. Note that we specify which category is considered “positive.”</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">train_con_mat =<span class="st"> </span><span class="kw">confusionMatrix</span>(train_tab, <span class="dt">positive =</span> <span class="st">&quot;Yes&quot;</span>)
(<span class="dt">test_con_mat =</span> <span class="kw">confusionMatrix</span>(test_tab, <span class="dt">positive =</span> <span class="st">&quot;Yes&quot;</span>))</code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##          actual
## predicted   No  Yes
##       No  4361   23
##       Yes  474  142
##                                          
##                Accuracy : 0.9006         
##                  95% CI : (0.892, 0.9088)
##     No Information Rate : 0.967          
##     P-Value [Acc &gt; NIR] : 1              
##                                          
##                   Kappa : 0.3287         
##  Mcnemar&#39;s Test P-Value : &lt;2e-16         
##                                          
##             Sensitivity : 0.8606         
##             Specificity : 0.9020         
##          Pos Pred Value : 0.2305         
##          Neg Pred Value : 0.9948         
##              Prevalence : 0.0330         
##          Detection Rate : 0.0284         
##    Detection Prevalence : 0.1232         
##       Balanced Accuracy : 0.8813         
##                                          
##        &#39;Positive&#39; Class : Yes            
## </code></pre>
<p>The most common, and most important metric is the <strong>classification accuracy</strong>.</p>
<p><span class="math display">\[
\text{Acc}(\hat{C}, \text{Data}) = \frac{1}{n}\sum_{i = 1}^{n}I(y_i = \hat{C}(\bf x_i))
\]</span></p>
<p>Here, <span class="math inline">\(I\)</span> is an indicator function, so we are essentially calculating the proportion of predicted classes that match the true class.</p>
<p><span class="math display">\[
I(y_i = \hat{C}(x)) = 
\begin{cases} 
  1 &amp; y_i = \hat{C}(x) \\
  0 &amp; y_i \neq \hat{C}(x) \\
\end{cases}
\]</span></p>
<p>It is also common to discuss the <strong>misclassification rate</strong>, or classification error, which is simply one minus the accuracy.</p>
<p>Like regression, we often split the data, and then consider Train Accuracy and Test Accuracy. Test Accuracy will be used as a measure of how well a classifier will work on unseen future data.</p>
<p><span class="math display">\[
\text{Acc}_{\text{Train}}(\hat{C}, \text{Train Data}) = \frac{1}{n_{Tr}}\sum_{i \in \text{Train}}^{}I(y_i = \hat{C}(\bf x_i))
\]</span></p>
<p><span class="math display">\[
\text{Acc}_{\text{Test}}(\hat{C}, \text{Test Data}) = \frac{1}{n_{Te}}\sum_{i \in \text{Test}}^{}I(y_i = \hat{C}(\bf x_i))
\]</span></p>
<p>These accuracy values are given by calling <code>confusionMatrix()</code>, or, if stored, can be accessed directly.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">train_con_mat$overall[<span class="st">&quot;Accuracy&quot;</span>]</code></pre></div>
<pre><code>## Accuracy 
##   0.8916</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">test_con_mat$overall[<span class="st">&quot;Accuracy&quot;</span>]</code></pre></div>
<pre><code>## Accuracy 
##   0.9006</code></pre>
<p>Sometimes guarding against making certain errors, FP or FN, are more important than simply finding the best accuracy. Thus, sometimes we will consider <strong>sensitivity</strong> and <strong>specificity</strong>.</p>
<p><span class="math display">\[
\text{Sens} = \text{True Positive Rate} = \frac{\text{TP}}{\text{P}} = \frac{\text{TP}}{\text{TP + FN}}
\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">test_con_mat$byClass[<span class="st">&quot;Sensitivity&quot;</span>]</code></pre></div>
<pre><code>## Sensitivity 
##   0.8606061</code></pre>
<p><span class="math display">\[
\text{Spec} = \text{True Negative Rate} = \frac{\text{TN}}{\text{N}} = \frac{\text{TN}}{\text{TN + FP}}
\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">test_con_mat$byClass[<span class="st">&quot;Specificity&quot;</span>]</code></pre></div>
<pre><code>## Specificity 
##   0.9019648</code></pre>
<p>Like accuracy, these can easily be found using <code>confusionMatrix()</code>.</p>
<p>When considering how well a classifier is performing, often, it is understandable to assume that any accuracy in a binary classification problem above 0.50, is a reasonable classifier. This however is not the case. We need to consider the <strong>balance</strong> of the classes. To do so, we look at the <strong>prevalence</strong> of positive cases.</p>
<p><span class="math display">\[
\text{Prev} = \frac{\text{P}}{\text{Total Obs}}= \frac{\text{TP + FN}}{\text{Total Obs}}
\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">train_con_mat$byClass[<span class="st">&quot;Prevalence&quot;</span>]</code></pre></div>
<pre><code>## Prevalence 
##     0.0336</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">test_con_mat$byClass[<span class="st">&quot;Prevalence&quot;</span>]</code></pre></div>
<pre><code>## Prevalence 
##      0.033</code></pre>
<p>Here, we see an extremely low prevalence, which suggests an even simpler classifier than our current based on <code>balance</code>.</p>
<p><span class="math display">\[
\hat{C}(\text{balance}) = 
\begin{cases} 
      \text{No} &amp; \text{balance} &gt; 1400 \\
      \text{No} &amp; \text{balance} \leq 1400 
   \end{cases}
\]</span></p>
<p>This classifier simply classifies all observations as negative cases.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pred_all_no =<span class="st"> </span><span class="kw">simple_class</span>(test_default$balance, 
                           <span class="dt">boundary =</span> <span class="dv">1400</span>, <span class="dt">above =</span> <span class="st">&quot;No&quot;</span>, <span class="dt">below =</span> <span class="st">&quot;No&quot;</span>)
<span class="kw">table</span>(<span class="dt">predicted =</span> pred_all_no, <span class="dt">actual =</span> test_default$default)</code></pre></div>
<pre><code>##          actual
## predicted   No  Yes
##        No 4835  165</code></pre>
<p>The <code>confusionMatrix()</code> function won’t even accept this table as input, because it isn’t a full matrix, only one row, so we calculate some metrics “by hand”.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="dv">4835</span> /<span class="st"> </span>(<span class="dv">4835</span> +<span class="st"> </span><span class="dv">165</span>) <span class="co"># test accuracy</span></code></pre></div>
<pre><code>## [1] 0.967</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="dv">1</span> -<span class="st"> </span><span class="fl">0.0336</span> <span class="co"># 1 - (train prevelence)</span></code></pre></div>
<pre><code>## [1] 0.9664</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="dv">1</span> -<span class="st"> </span><span class="fl">0.033</span> <span class="co"># 1 - (test prevelence)</span></code></pre></div>
<pre><code>## [1] 0.967</code></pre>
<p>This classifier does better than the previous. But the point is, in reality, to create a good classifier, we should obtain a test accuracy better than 0.967, which is obtained by simply manipulating the prevalence. Next chapter, we’ll introduce much better classifiers which should have no problem accomplishing this task.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="simulating-the-biasvariance-tradeoff.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="logistic-regression.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/daviddalpiaz/r4sl/edit/master/07-classification.Rmd",
"text": "Edit"
},
"download": null,
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
